{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80e290ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "CustomJob [projects/995291332977/locations/us-central1/customJobs/7211286648745623552] is submitted successfully.\n",
      "\n",
      "Your job is still active. You may view the status of your job with the command\n",
      "\n",
      "  $ gcloud ai custom-jobs describe projects/995291332977/locations/us-central1/customJobs/7211286648745623552\n",
      "\n",
      "or continue streaming the logs with the command\n",
      "\n",
      "  $ gcloud ai custom-jobs stream-logs projects/995291332977/locations/us-central1/customJobs/7211286648745623552\n"
     ]
    }
   ],
   "source": [
    "# creating my first job\n",
    "!gcloud ai custom-jobs create \\\n",
    "  --region='us-central1' \\\n",
    "  --display-name='training mcfl synthetic poison' \\\n",
    "  --worker-pool-spec=machine-type='c2-standard-16',replica-count=1,container-image-uri=gcr.io/robust-multicenter-fl/train_syn_p_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b21edbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m\u001b[1mNAME\u001b[m\n",
      "    gcloud ai custom-jobs create - create a new custom job\n",
      "\n",
      "\u001b[m\u001b[1mSYNOPSIS\u001b[m\n",
      "    \u001b[1mgcloud ai custom-jobs create\u001b[m \u001b[1m--display-name\u001b[m=\u001b[4mDISPLAY_NAME\u001b[m\n",
      "        (\u001b[1m--config\u001b[m=\u001b[4mCONFIG\u001b[m \u001b[1m--worker-pool-spec\u001b[m=[\u001b[4mWORKER_POOL_SPEC\u001b[m,...])\n",
      "        [\u001b[1m--args\u001b[m=[\u001b[4mARG\u001b[m,...]] [\u001b[1m--command\u001b[m=[\u001b[4mCOMMAND\u001b[m,...]] [\u001b[1m--network\u001b[m=\u001b[4mNETWORK\u001b[m]\n",
      "        [\u001b[1m--python-package-uris\u001b[m=[\u001b[4mPYTHON_PACKAGE_URIS\u001b[m,...]] [\u001b[1m--region\u001b[m=\u001b[4mREGION\u001b[m]\n",
      "        [\u001b[1m--service-account\u001b[m=\u001b[4mSERVICE_ACCOUNT\u001b[m]\n",
      "        [\u001b[1m--kms-key\u001b[m=\u001b[4mKMS_KEY\u001b[m : \u001b[1m--kms-keyring\u001b[m=\u001b[4mKMS_KEYRING\u001b[m\n",
      "          \u001b[1m--kms-location\u001b[m=\u001b[4mKMS_LOCATION\u001b[m \u001b[1m--kms-project\u001b[m=\u001b[4mKMS_PROJECT\u001b[m]\n",
      "        [\u001b[4mGCLOUD_WIDE_FLAG ...\u001b[m]\n",
      "\n",
      "\u001b[m\u001b[1mDESCRIPTION\u001b[m\n",
      "    This command will attempt to run the custom job immediately upon creation.\n",
      "\n",
      "\u001b[m\u001b[1mEXAMPLES\u001b[m\n",
      "    To create a job under project \u001b[1m\u001b[1;4mexample\u001b[1m\u001b[m in region \u001b[1m\u001b[1;4mus-central1\u001b[1m\u001b[m, run:\n",
      "\n",
      "        $ gcloud ai custom-jobs create --region=us-central1 --project=example\n",
      "        --worker-pool-spec=replica-count=1,machine-type='n1-highmem-2',container-image-uri='gcr.io/ucaip-test/ucaip-training-test'\n",
      "        --display-name=test\n",
      "\n",
      "\u001b[m\u001b[1mREQUIRED FLAGS\u001b[m\n",
      "     \u001b[1m--display-name\u001b[m=\u001b[4mDISPLAY_NAME\u001b[m\n",
      "        Display name of the custom job to create.\n",
      "\n",
      "     Worker pool specification.\n",
      "\n",
      "     At least one of these must be specified:\n",
      "\n",
      "       \u001b[1m--config\u001b[m=\u001b[4mCONFIG\u001b[m\n",
      "          Path to the job configuration file. This file should be a YAML\n",
      "          document containing a `CustomJobSpec`\n",
      "          (https://cloud.google.com/vertex-ai/docs/reference/rest/v1/CustomJobSpec).\n",
      "          If an option is specified both in the configuration file **and** via\n",
      "          command-line arguments, the command-line arguments override the\n",
      "          configuration file. Note that keys with underscore are invalid.\n",
      "\n",
      "          Example(YAML):\n",
      "\n",
      "              workerPoolSpecs:\n",
      "                machineSpec:\n",
      "                  machineType: n1-highmem-2\n",
      "                replicaCount: 1\n",
      "                containerSpec:\n",
      "                  imageUri: gcr.io/ucaip-test/ucaip-training-test\n",
      "                  args:\n",
      "                  - port=8500\n",
      "                  command:\n",
      "                  - start\n",
      "\n",
      "       \u001b[1m--worker-pool-spec\u001b[m=[\u001b[4mWORKER_POOL_SPEC\u001b[m,...]\n",
      "          Define the worker pool configuration used by the custom job. You can\n",
      "          specify multiple worker pool specs in order to create a custom job\n",
      "          with multiple worker pools.\n",
      "\n",
      "          The spec can contain the following fields:\n",
      "\n",
      "           \u001b[1mmachine-type\u001b[m\n",
      "              (Required): The type of the machine. see\n",
      "              https://cloud.google.com/vertex-ai/docs/training/configure-compute#machine-types\n",
      "              for supported types. This is corresponding to the\n",
      "              \u001b[1mmachineSpec.machineType\u001b[m field in \u001b[1mWorkerPoolSpec\u001b[m API message.\n",
      "           \u001b[1mreplica-count\u001b[m\n",
      "              The number of worker replicas to use for this worker pool, by\n",
      "              default the value is 1. This is corresponding to the \u001b[1mreplicaCount\u001b[m\n",
      "              field in \u001b[1mWorkerPoolSpec\u001b[m API message.\n",
      "           \u001b[1maccelerator-type\u001b[m\n",
      "              The type of GPUs. see\n",
      "              https://cloud.google.com/vertex-ai/docs/training/configure-compute#specifying_gpus\n",
      "              for more requirements. This is corresponding to the\n",
      "              \u001b[1mmachineSpec.acceleratorType\u001b[m field in \u001b[1mWorkerPoolSpec\u001b[m API message.\n",
      "           \u001b[1maccelerator-count\u001b[m\n",
      "              The number of GPUs for each VM in the worker pool to use, by\n",
      "              default the value if 1. This is corresponding to the\n",
      "              \u001b[1mmachineSpec.acceleratorCount\u001b[m field in \u001b[1mWorkerPoolSpec\u001b[m API message.\n",
      "           \u001b[1mcontainer-image-uri\u001b[m\n",
      "              The URI of a container image to be directly run on each worker\n",
      "              replica. This is corresponding to the \u001b[1mcontainerSpec.imageUri\u001b[m\n",
      "              field in \u001b[1mWorkerPoolSpec\u001b[m API message.\n",
      "           \u001b[1mexecutor-image-uri\u001b[m\n",
      "              The URI of a container image that will run the provided package.\n",
      "              This is corresponding to the \u001b[1mpythonPackageSpec.executorImageUri\u001b[m\n",
      "              field in \u001b[1mWorkerPoolSpec\u001b[m API message.\n",
      "           \u001b[1mpython-module\u001b[m\n",
      "              The Python module name to run within the provided package. This\n",
      "              is corresponding to the \u001b[1mpythonPackageSpec.pythonModule\u001b[m field in\n",
      "              \u001b[1mWorkerPoolSpec\u001b[m API message.\n",
      "\n",
      "              For example:\n",
      "              \u001b[1m--worker-pool-spec=replica-count=1,machine-type=n1-highmem-2,container-image-uri=gcr.io/ucaip-test/ucaip-training-test\u001b[m\n",
      "\n",
      "\u001b[m\u001b[1mOPTIONAL FLAGS\u001b[m\n",
      "     \u001b[1m--args\u001b[m=[\u001b[4mARG\u001b[m,...]\n",
      "        Comma-separated arguments passed to containers or python tasks.\n",
      "\n",
      "     \u001b[1m--command\u001b[m=[\u001b[4mCOMMAND\u001b[m,...]\n",
      "        Command to be invoked when containers are started. It overrides the\n",
      "        entrypoint instruction in Dockerfile when provided.\n",
      "\n",
      "     \u001b[1m--network\u001b[m=\u001b[4mNETWORK\u001b[m\n",
      "        Full name of the Google Compute Engine network to which the Job is\n",
      "        peered with. Private services access must already have been configured.\n",
      "        If unspecified, the Job is not peered with any network.\n",
      "\n",
      "     \u001b[1m--python-package-uris\u001b[m=[\u001b[4mPYTHON_PACKAGE_URIS\u001b[m,...]\n",
      "        The common Python package URIs to be used for training with a pre-built\n",
      "        container image. e.g. \u001b[1m--python-package-uri=path1,path2\u001b[m If you are using\n",
      "        multiple worker pools and want to specify a different Python packag fo\n",
      "        reach pool, use \u001b[1m--config\u001b[m instead.\n",
      "\n",
      "     Region resource - Cloud region to create a custom job. This represents a\n",
      "     Cloud resource. (NOTE) Some attributes are not given arguments in this\n",
      "     group but can be set in other ways. To set the \u001b[1mproject\u001b[m attribute:\n",
      "      ◆ provide the argument \u001b[1m--region\u001b[m on the command line with a fully\n",
      "        specified name;\n",
      "      ◆ set the property \u001b[1mai/region\u001b[m with a fully specified name;\n",
      "      ◆ choose one from the prompted list of available regions with a fully\n",
      "        specified name;\n",
      "      ◆ provide the argument \u001b[1m--project\u001b[m on the command line;\n",
      "      ◆ set the property \u001b[1mcore/project\u001b[m.\n",
      "\n",
      "       \u001b[1m--region\u001b[m=\u001b[4mREGION\u001b[m\n",
      "          ID of the region or fully qualified identifier for the region. To set\n",
      "          the \u001b[1mregion\u001b[m attribute:\n",
      "          ▸ provide the argument \u001b[1m--region\u001b[m on the command line;\n",
      "          ▸ set the property \u001b[1mai/region\u001b[m;\n",
      "          ▸ choose one from the prompted list of available regions.\n",
      "\n",
      "     \u001b[1m--service-account\u001b[m=\u001b[4mSERVICE_ACCOUNT\u001b[m\n",
      "        The email address of a service account to use when running the training\n",
      "        appplication. You must have the \u001b[1miam.serviceAccounts.actAs\u001b[m permission\n",
      "        for the specified service account.\n",
      "\n",
      "     Key resource - The Cloud KMS (Key Management Service) cryptokey that will\n",
      "     be used to protect the custom job. The 'Vertex AI Service Agent' service\n",
      "     account must hold permission 'Cloud KMS CryptoKey Encrypter/Decrypter'.\n",
      "     The arguments in this group can be used to specify the attributes of this\n",
      "     resource.\n",
      "\n",
      "       \u001b[1m--kms-key\u001b[m=\u001b[4mKMS_KEY\u001b[m\n",
      "          ID of the key or fully qualified identifier for the key. To set the\n",
      "          \u001b[1mkms-key\u001b[m attribute:\n",
      "          ▸ provide the argument \u001b[1m--kms-key\u001b[m on the command line.\n",
      "\n",
      "          This flag must be specified if any of the other arguments in this\n",
      "          group are specified.\n",
      "\n",
      "       \u001b[1m--kms-keyring\u001b[m=\u001b[4mKMS_KEYRING\u001b[m\n",
      "          The KMS keyring of the key. To set the \u001b[1mkms-keyring\u001b[m attribute:\n",
      "          ▸ provide the argument \u001b[1m--kms-key\u001b[m on the command line with a fully\n",
      "            specified name;\n",
      "          ▸ provide the argument \u001b[1m--kms-keyring\u001b[m on the command line.\n",
      "\n",
      "       \u001b[1m--kms-location\u001b[m=\u001b[4mKMS_LOCATION\u001b[m\n",
      "          The Cloud location for the key. To set the \u001b[1mkms-location\u001b[m attribute:\n",
      "          ▸ provide the argument \u001b[1m--kms-key\u001b[m on the command line with a fully\n",
      "            specified name;\n",
      "          ▸ provide the argument \u001b[1m--kms-location\u001b[m on the command line.\n",
      "\n",
      "       \u001b[1m--kms-project\u001b[m=\u001b[4mKMS_PROJECT\u001b[m\n",
      "          The Cloud project for the key. To set the \u001b[1mkms-project\u001b[m attribute:\n",
      "          ▸ provide the argument \u001b[1m--kms-key\u001b[m on the command line with a fully\n",
      "            specified name;\n",
      "          ▸ provide the argument \u001b[1m--kms-project\u001b[m on the command line;\n",
      "          ▸ set the property \u001b[1mcore/project\u001b[m.\n",
      "\n",
      "\u001b[m\u001b[1mGCLOUD WIDE FLAGS\u001b[m\n",
      "    These flags are available to all commands: --account, --billing-project,\n",
      "    --configuration, --flags-file, --flatten, --format, --help,\n",
      "    --impersonate-service-account, --log-http, --project, --quiet,\n",
      "    --trace-token, --user-output-enabled, --verbosity.\n",
      "\n",
      "    Run \u001b[1m$ gcloud help\u001b[m for details.\n",
      "\n",
      "\u001b[m\u001b[1mNOTES\u001b[m\n",
      "    These variants are also available:\n",
      "\n",
      "        $ gcloud alpha ai custom-jobs create\n",
      "\n",
      "        $ gcloud beta ai custom-jobs create\n",
      "\n",
      "\u001b[m"
     ]
    }
   ],
   "source": [
    "!gcloud ai custom-jobs create --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b751770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
